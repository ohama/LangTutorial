{
open System
open FSharp.Text.Lexing
open Parser  // Import token types from generated Parser module

// Helper to get lexeme as string
let lexeme (lexbuf: LexBuffer<_>) =
    LexBuffer<_>.LexemeString lexbuf
}

// Character class definitions
let digit = ['0'-'9']
let whitespace = [' ' '\t']
let newline = ('\n' | '\r' '\n')
let letter = ['a'-'z' 'A'-'Z']
let ident_start = letter | '_'
let ident_char = letter | digit | '_'

// Lexer rules
rule tokenize = parse
    | whitespace+   { tokenize lexbuf }           // Skip whitespace
    | newline       { tokenize lexbuf }           // Skip newlines
    | digit+        { NUMBER (Int32.Parse(lexeme lexbuf)) }  // Integer literal
    // Keywords MUST come before identifier pattern
    | "true"        { TRUE }
    | "false"       { FALSE }
    | "if"          { IF }
    | "then"        { THEN }
    | "else"        { ELSE }
    | "let"         { LET }
    | "in"          { IN }
    // Phase 5: Function keywords
    | "fun"         { FUN }
    | "rec"         { REC }
    // Identifier: starts with letter or underscore
    | ident_start ident_char* { IDENT (lexeme lexbuf) }
    // Multi-char operators MUST come before single-char
    | "<="          { LE }
    | ">="          { GE }
    | "<>"          { NE }
    | "&&"          { AND }
    | "||"          { OR }
    // Phase 5: Arrow for lambda expressions
    | "->"          { ARROW }
    // Comments (MUST come before operators to match first)
    | "//" [^ '\n' '\r']*  { tokenize lexbuf }   // Skip single-line comment
    | "(*"          { block_comment 1 lexbuf }   // Start block comment, depth=1
    // Single-char operators
    | '+'           { PLUS }
    | '-'           { MINUS }
    | '*'           { STAR }
    | '/'           { SLASH }
    | '<'           { LT }
    | '>'           { GT }
    | '('           { LPAREN }
    | ')'           { RPAREN }
    | '='           { EQUALS }
    | eof           { EOF }                       // End of input

// Block comment handler with nesting support
and block_comment depth = parse
    | "(*"    { block_comment (depth + 1) lexbuf }     // Nested open: increase depth
    | "*)"    { if depth = 1 then tokenize lexbuf     // Close: if depth=1, return to tokenize
                else block_comment (depth - 1) lexbuf } // else decrease depth
    | newline { block_comment depth lexbuf }           // Continue on newline
    | eof     { failwith "Unterminated comment" }      // Error on EOF
    | _       { block_comment depth lexbuf }           // Skip any other char

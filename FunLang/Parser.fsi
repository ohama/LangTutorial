// Signature file for parser generated by fsyacc
module Parser
type token = 
  | EOF
  | TYPE_VAR of (string)
  | TYPE_INT
  | TYPE_BOOL
  | TYPE_STRING
  | TYPE_LIST
  | COLON
  | MATCH
  | WITH
  | PIPE
  | LBRACKET
  | RBRACKET
  | CONS
  | UNDERSCORE
  | COMMA
  | FUN
  | REC
  | ARROW
  | AND
  | OR
  | LT
  | GT
  | LE
  | GE
  | NE
  | TRUE
  | FALSE
  | IF
  | THEN
  | ELSE
  | LET
  | IN
  | EQUALS
  | LPAREN
  | RPAREN
  | PLUS
  | MINUS
  | STAR
  | SLASH
  | STRING of (string)
  | IDENT of (string)
  | NUMBER of (int)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_TYPE_VAR
    | TOKEN_TYPE_INT
    | TOKEN_TYPE_BOOL
    | TOKEN_TYPE_STRING
    | TOKEN_TYPE_LIST
    | TOKEN_COLON
    | TOKEN_MATCH
    | TOKEN_WITH
    | TOKEN_PIPE
    | TOKEN_LBRACKET
    | TOKEN_RBRACKET
    | TOKEN_CONS
    | TOKEN_UNDERSCORE
    | TOKEN_COMMA
    | TOKEN_FUN
    | TOKEN_REC
    | TOKEN_ARROW
    | TOKEN_AND
    | TOKEN_OR
    | TOKEN_LT
    | TOKEN_GT
    | TOKEN_LE
    | TOKEN_GE
    | TOKEN_NE
    | TOKEN_TRUE
    | TOKEN_FALSE
    | TOKEN_IF
    | TOKEN_THEN
    | TOKEN_ELSE
    | TOKEN_LET
    | TOKEN_IN
    | TOKEN_EQUALS
    | TOKEN_LPAREN
    | TOKEN_RPAREN
    | TOKEN_PLUS
    | TOKEN_MINUS
    | TOKEN_STAR
    | TOKEN_SLASH
    | TOKEN_STRING
    | TOKEN_IDENT
    | TOKEN_NUMBER
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_Expr
    | NONTERM_Term
    | NONTERM_Factor
    | NONTERM_AppExpr
    | NONTERM_Atom
    | NONTERM_ExprList
    | NONTERM_TuplePattern
    | NONTERM_PatternList
    | NONTERM_Pattern
    | NONTERM_MatchClauses
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> (Ast.Expr) 
